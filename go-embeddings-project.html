<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Go Embeddings Library - Owen Jones</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <a href="index.html" class="logo">Owen Jones</a>
            <nav>
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html">Projects</a>
                <a href="contact.html">Contact</a>
            </nav>
        </header>

        <main>
            <h1>Go Embeddings Library</h1>

            <div class="status-badge">
                In Development
            </div>

            <section class="project-section">
                <h2>Overview</h2>
                <p>A high-performance, production-ready embedding service written in Go, supporting multiple transformer models with MacOS Metal acceleration. The library combines efficient memory management, optimized batch processing, and hardware acceleration to deliver fast, reliable text embeddings for production environments.</p>
            </section>

            <section class="project-section">
                <h2>Key Features</h2>
                <ul class="feature-list">
                    <li>Production-ready transformer-based text embeddings with comprehensive error handling and logging</li>
                    <li>MacOS Metal/CoreML hardware acceleration with ANE support, delivering optimized performance on Apple Silicon</li>
                    <li>Multi-model support with dynamic loading and efficient model management</li>
                    <li>Optimized batch processing with auto-tuning based on input characteristics</li>
                    <li>Two-level caching system (memory + disk) with LRU eviction for improved performance</li>
                    <li>Prometheus metrics integration for comprehensive monitoring</li>
                    <li>Support for both synchronous and asynchronous operations with worker pools</li>
                    <li>Intelligent chunking support for processing long documents</li>
                    <li>Thread-safe implementation with graceful shutdown capabilities</li>
                </ul>
            </section>

            <section class="project-section">
                <h2>Example Usage</h2>
                <h3>Basic Implementation</h3>
                <p>The library can be used both as a standalone service and integrated into existing Go applications. Here's a basic example:</p>
                <pre class="code-block">
package main

import (
    "context"
    "fmt"
    "log"
    "time"

    "github.com/objones25/go-embeddings/pkg/embedding"
)

func main() {
    // Initialize configuration
    config := &embedding.Config{
        ModelPath:         "./models/all-MiniLM-L6-v2",
        MaxSequenceLength: 512,
        Dimension:        384,  // 384 for MiniLM-L6
        BatchSize:        32,
        EnableMetal:      true,  // Enable CoreML
        CoreMLConfig: &embedding.CoreMLConfig{
            EnableCaching: true,
            RequireANE:    false,
        },
        Options: embedding.Options{
            CacheEnabled:   true,
            Normalize:      true,
            PadToMaxLength: false,
        },
    }

    // Create service with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    service, err := embedding.NewService(ctx, config)
    if err != nil {
        log.Fatalf("Failed to create service: %v", err)
    }
    defer service.Close()

    // Generate single embedding
    text := "Hello, world!"
    vector, err := service.Embed(ctx, text)
    if err != nil {
        log.Fatalf("Failed to generate embedding: %v", err)
    }
    fmt.Printf("Single embedding (len=%d): %v\n", len(vector), vector[:5])
}</pre>
            </section>

            <section class="project-section">
                <h2>Advanced Features</h2>
                
                <h3>Asynchronous Batch Processing</h3>
                <p>For handling large volumes of text, the library provides asynchronous batch processing capabilities:</p>
                <pre class="code-block">
// Initialize channels for results and errors
results := make(chan embedding.Result)
errors := make(chan error)

// Process texts asynchronously
texts := []string{
    "First text to embed",
    "Second text to embed",
    "Third text to embed",
}

err := service.BatchEmbedAsync(ctx, texts, results, errors)
if err != nil {
    log.Fatal(err)
}

// Process results as they arrive
for i := 0; i < len(texts); i++ {
    select {
    case result := <-results:
        fmt.Printf("Embedding: %v\n", result.Embedding[:5])
    case err := <-errors:
        fmt.Printf("Error: %v\n", err)
    case <-ctx.Done():
        fmt.Println("Operation timed out")
        return
    }
}</pre>

                <h3>Document Chunking</h3>
                <p>For processing longer documents, the library includes intelligent chunking capabilities:</p>
                <pre class="code-block">
// Initialize tokenizer
tokConfig := embedding.TokenizerConfig{
    ModelID:        "all-MiniLM-L6-v2",
    SequenceLength: 512,
}
tokenizer, _ := embedding.NewTokenizer(tokConfig)

// Configure chunking
opts := embedding.DefaultChunkingOptions()
opts.Strategy = embedding.ChunkByParagraph
opts.MaxTokens = 256

// Process long document
longText := `First paragraph with content.

Second paragraph with different content.
This is still part of the second paragraph.

Third paragraph here.`

chunks, err := tokenizer.ChunkDocument(longText, opts)
if err != nil {
    log.Fatal(err)
}</pre>
            </section>

            <section class="project-section">
                <h2>Technical Capabilities</h2>
                <div class="metrics-grid">
                    <div class="metric-card">
                        <span class="metric-label">Vector Operations</span>
                        <span class="metric-description">SIMD-optimized vector similarity computations with multiple distance metrics</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">Index Management</span>
                        <span class="metric-description">Efficient vector storage with dynamic index updates and persistence</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">Search Capabilities</span>
                        <span class="metric-description">Configurable KNN search with filtering and metadata support</span>
                    </div>
                </div>
            </section>

            <section class="project-section">
                <h2>Development Status</h2>
                <ul class="status-list">
                    <li>Currently optimizing CoreML integration for improved performance metrics and working on expanding model support</li>
                    <li>Implementing advanced caching strategies for better resource utilization</li>
                    <li>Developing comprehensive documentation and usage examples</li>
                    <li>Fine-tuning batch processing performance for various input scenarios</li>
                </ul>
            </section>

            <a href="https://github.com/objones25/go-embeddings/tree/main" class="github-link" target="_blank">View on GitHub →</a>
        </main>

        <footer>
            © 2024 Owen Jones. All rights reserved.
        </footer>
    </div>
</body>
</html>